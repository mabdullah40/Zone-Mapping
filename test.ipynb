{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"name\": \"Amigu-Production\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"rds_mysql\",\n",
      "    \"id\": 18\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Billing Production\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"rds_mysql\",\n",
      "    \"id\": 8\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Datawarehouse\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"rds_mysql\",\n",
      "    \"id\": 6\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Dimagh Production\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"rds_mysql\",\n",
      "    \"id\": 2\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Ledger Production\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"rds_mysql\",\n",
      "    \"id\": 4\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"rider_db_notification\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"mysql\",\n",
      "    \"id\": 15\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"rider_db_orders\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"mysql\",\n",
      "    \"id\": 14\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"rider_db_routing\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"mysql\",\n",
      "    \"id\": 16\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"rider_db_usermgt\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"mysql\",\n",
      "    \"id\": 17\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"staging_db_orders\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"mysql\",\n",
      "    \"id\": 13\n",
      "  },\n",
      "  {\n",
      "    \"name\": \"Whatsapp\",\n",
      "    \"pause_reason\": null,\n",
      "    \"syntax\": \"sql\",\n",
      "    \"paused\": 0,\n",
      "    \"view_only\": false,\n",
      "    \"type\": \"rds_mysql\",\n",
      "    \"id\": 5\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Replace these with your Redash instance details\n",
    "REDASH_HOST = \"https://redash.truckitin.ai\"\n",
    "API_KEY = \"loMLO5S6tcTusPWt5dcExEA4qMaRRQBbrkbcSuLx\"\n",
    "\n",
    "# URL for the data sources API\n",
    "url = f\"{REDASH_HOST}/api/data_sources\"\n",
    "\n",
    "# Headers with the API key\n",
    "headers = {\"Authorization\": f\"Key {API_KEY}\"}\n",
    "\n",
    "# Make the request\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check for a successful response\n",
    "if response.status_code == 200:\n",
    "    # Parse the JSON response\n",
    "    data_sources = response.json()\n",
    "    print(json.dumps(data_sources, indent=2))\n",
    "else:\n",
    "    print(f\"Failed to get data sources: {response.status_code} - {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m data_source_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m14\u001b[39m  \u001b[38;5;66;03m# You need to know this beforehand\u001b[39;00m\n\u001b[0;32m     40\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM OrderDetails LIMIT 10\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 42\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_source_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "Cell \u001b[1;32mIn[3], line 16\u001b[0m, in \u001b[0;36mrun_query\u001b[1;34m(api_key, query, data_source_id)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create and execute the query\u001b[39;00m\n\u001b[0;32m     11\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/queries\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     13\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[0;32m     14\u001b[0m     json\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_source_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: data_source_id},\n\u001b[0;32m     15\u001b[0m )\n\u001b[1;32m---> 16\u001b[0m query_id \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Execute the query\u001b[39;00m\n\u001b[0;32m     19\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/queries/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/results\u001b[39m\u001b[38;5;124m\"\u001b[39m, headers\u001b[38;5;241m=\u001b[39mheaders)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'id'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run_query(api_key, query, data_source_id):\n",
    "    base_url = \"https://redash.truckitin.ai/api\"\n",
    "    headers = {\"Authorization\": f\"Key {api_key}\"}\n",
    "\n",
    "    # Create and execute the query\n",
    "    response = requests.post(\n",
    "        f\"{base_url}/queries\",\n",
    "        headers=headers,\n",
    "        json={\"query\": query, \"data_source_id\": data_source_id},\n",
    "    )\n",
    "    query_id = response.json()[\"id\"]\n",
    "\n",
    "    # Execute the query\n",
    "    response = requests.post(f\"{base_url}/queries/{query_id}/results\", headers=headers)\n",
    "    job = response.json()[\"job\"]\n",
    "\n",
    "    # Poll for query results\n",
    "    while job[\"status\"] not in (3, 4):  # 3: completed, 4: failed\n",
    "        response = requests.get(f'{base_url}/jobs/{job[\"id\"]}', headers=headers)\n",
    "        job = response.json()[\"job\"]\n",
    "        time.sleep(1)\n",
    "\n",
    "    if job[\"status\"] == 3:\n",
    "        results = requests.get(\n",
    "            f\"{base_url}/queries/{query_id}/results.json\", headers=headers\n",
    "        ).json()[\"query_result\"][\"data\"]\n",
    "        return pd.DataFrame(results[\"rows\"])\n",
    "    else:\n",
    "        raise Exception(\"Query execution failed.\")\n",
    "\n",
    "\n",
    "# Usage example\n",
    "api_key = \"loMLO5S6tcTusPWt5dcExEA4qMaRRQBbrkbcSuLx\"\n",
    "data_source_id = 14  # You need to know this beforehand\n",
    "query = \"SELECT * FROM OrderDetails LIMIT 10\"\n",
    "\n",
    "df = run_query(api_key, query, data_source_id)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-05 12:42:13,988 - INFO - Query executed successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   transit_received  area_id  city_id  delivery_type_id  shipping_term_id  \\\n",
      "0                 1     6209      772                 2                 1   \n",
      "1                 0     2012        1                 2                 1   \n",
      "2                 1     6209      772                 2                 1   \n",
      "3                 0      364        2                 2                 1   \n",
      "4                 1      561        3                 2                 1   \n",
      "\n",
      "   order_status_id_prev sort_addr_id province_name_dest_city  \\\n",
      "0                   8.0         None                  Punjab   \n",
      "1                   8.0         None                   Sindh   \n",
      "2                  18.0         None                  Punjab   \n",
      "3                  18.0         None                  Punjab   \n",
      "4                  18.0         None                   Sindh   \n",
      "\n",
      "   payment_mode_rider  call_origin  ...  payment_mode_customer_title  \\\n",
      "0                 2.0          203  ...                         None   \n",
      "1                 2.0          203  ...                         None   \n",
      "2                 2.0          200  ...                         None   \n",
      "3                 2.0          200  ...                         None   \n",
      "4                 2.0          203  ...                         None   \n",
      "\n",
      "   consignment_id time_slot_id           created_at  ref_number delivery_code  \\\n",
      "0       WR4025670            1  2023-01-01T19:02:07       BP-96          8017   \n",
      "1       WR4025672            1  2023-01-01T19:02:10   BP-169/01          8806   \n",
      "2       WR4025673            1  2023-01-01T19:02:12           0          9427   \n",
      "3       WR4025674            1  2023-01-01T19:02:21       BP-96          7065   \n",
      "4       WR4025675            1  2023-01-01T19:02:54   BP-195/01          3355   \n",
      "\n",
      "     shipping_term_title amount_collected  ofd_datetime  est_dim_height  \n",
      "0  Collect from Customer              0.0          None            None  \n",
      "1  Collect from Customer            679.0          None            None  \n",
      "2  Collect from Customer           1859.0          None            None  \n",
      "3  Collect from Customer            900.0          None            None  \n",
      "4  Collect from Customer           1640.0          None            None  \n",
      "\n",
      "[5 rows x 135 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\"\n",
    ")\n",
    "\n",
    "REDASH_HOST = \"https://redash.truckitin.ai\"\n",
    "API_KEY = \"loMLO5S6tcTusPWt5dcExEA4qMaRRQBbrkbcSuLx\"\n",
    "DATA_SOURCE_ID = \"14\"\n",
    "\n",
    "# Ad-hoc SQL query\n",
    "query = \"SELECT * FROM OrderDetails LIMIT 10\"\n",
    "\n",
    "# URL for running the query\n",
    "url = f\"{REDASH_HOST}/api/query_results\"\n",
    "\n",
    "# Headers with the API key\n",
    "headers = {\"Authorization\": f\"Key {API_KEY}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Payload with the data source ID and query\n",
    "payload = {\"data_source_id\": DATA_SOURCE_ID, \"query\": query}\n",
    "\n",
    "\n",
    "def run_query(url, headers, payload):\n",
    "    try:\n",
    "        # Make the request\n",
    "        response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "\n",
    "        # Check for a successful response\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Parse the JSON response\n",
    "        result = response.json()\n",
    "\n",
    "        # Extract the query results\n",
    "        query_results = result[\"query_result\"][\"data\"][\"rows\"]\n",
    "\n",
    "        # Convert the query results to a Pandas DataFrame\n",
    "        df = pd.DataFrame(query_results)\n",
    "\n",
    "        return df\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Request failed: {e}\")\n",
    "        return None\n",
    "    except KeyError as e:\n",
    "        logging.error(f\"Unexpected response format: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Run the query and get the DataFrame\n",
    "df = run_query(url, headers, payload)\n",
    "\n",
    "if df is not None:\n",
    "    logging.info(\"Query executed successfully.\")\n",
    "    # Proceed with further processing on df\n",
    "    print(df.head())\n",
    "else:\n",
    "    logging.error(\"Query execution failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
